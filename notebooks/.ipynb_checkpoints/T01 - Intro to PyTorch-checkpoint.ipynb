{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b10504",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7bcc3",
   "metadata": {},
   "source": [
    "## 1. Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853edec",
   "metadata": {},
   "source": [
    "[Kaggle Page](https://www.kaggle.com/competitions/digit-recognizer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd160d",
   "metadata": {},
   "source": [
    "## 2. Reformat the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9fa4d",
   "metadata": {},
   "source": [
    "We must reformat the data so that we can look at a single image/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install matplotlib pandas torch torchvision Pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e93545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bb6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open csv as pandas dataframe\n",
    "data_dir = \"/Users/amc/Downloads/digit-recognizer\"\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "train_df = pd.read_csv(train_file)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29598b",
   "metadata": {},
   "source": [
    "### Split up data into train/val subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels as an array (could probably be a list instead if you prefer)\n",
    "y = train_df['label']\n",
    "\n",
    "# split pixel info as an array\n",
    "X = train_df.drop(columns=['label'])\n",
    "\n",
    "# split data into train/val/test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check lengths of datasets\n",
    "print(f\"length of train set: {len(y_train)}\")\n",
    "print(f\"length of val set: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d69e1-b577-4861-9497-a8146be43cd5",
   "metadata": {},
   "source": [
    "### Write new dataframes to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e245218-43e3-494f-ac27-9ff2bd55cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/amc/Downloads/digit-recognizer/processed\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# merge back into dataframes\n",
    "column_names = train_df.columns.tolist()\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "val_df = pd.concat([y_val, X_val], axis=1)\n",
    "\n",
    "# save to csv files for loading into separate Dataset objects\n",
    "train_df.to_csv(os.path.join(data_dir, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(data_dir, \"val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1140534",
   "metadata": {},
   "source": [
    "### Withdraw 1 image+label pair for a given row (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42466a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify index (row number, starting at 0)\n",
    "idx = 14\n",
    "\n",
    "# save and print label\n",
    "label = train_df.iloc[idx]['label']\n",
    "\n",
    "# save and print image with matplotlib pyplot\n",
    "image = train_df.iloc[idx].to_numpy()  # <- save row as numpy array\n",
    "image = image[1:]  # <- remove label value\n",
    "image = image.reshape(28,28)  # <- reshape numpy array into a 28x28 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display image+label pair\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9a3c5",
   "metadata": {},
   "source": [
    "## 3. Make a custom PyTorch Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac5629",
   "metadata": {},
   "source": [
    "The PyTorch Dataset class automates what we did above.\n",
    "\n",
    "This is a class where you define how to get the image and label for any given index. \n",
    "\n",
    "The index starts at 0 and ends at x-1, where x=number of total samples\n",
    "\n",
    "PyTorch tutorial: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8761099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, csv_file: str, transform=None):\n",
    "        \"\"\" Dataset of grayscale number images.\n",
    "        \n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Data transform.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        \n",
    "        # Extract label\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        # Extract image\n",
    "        image = self.df.iloc[idx].to_numpy(dtype=np.float32)  \n",
    "        image = image[1:]\n",
    "        image = image.reshape(28,28)\n",
    "        \n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a331f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "train_dataset = DigitsDataset(csv_file=os.path.join(data_dir, \"train.csv\"), \n",
    "                              transform=T.Compose([\n",
    "                                  T.ToTensor()\n",
    "                              ]))\n",
    "val_dataset = DigitsDataset(csv_file=os.path.join(data_dir, \"val.csv\"), \n",
    "                            transform=T.Compose([\n",
    "                                T.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec82e6",
   "metadata": {},
   "source": [
    "## 4. Make PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834bf0d",
   "metadata": {},
   "source": [
    "The PyTorch DataLoader is a class where you specify batch number and it hands a batch of images for processing through the model. \n",
    "\n",
    "A batch is a set of images to be used for each training iteration. The number of images used for each batch is the batch size. \n",
    "\n",
    "Each training iteration is an \"epoch\", which is where the computer runs through all the images in the dataset once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b172454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1477a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view an image from the dataloader (NOTE: only works if num_workers=0)\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "example_label = label_batch[0]\n",
    "example_img = img_batch[0].squeeze()\n",
    "\n",
    "# show image\n",
    "plt.imshow(example_img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {example_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1dd624",
   "metadata": {},
   "source": [
    "## 5. Make a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f2549-7d3f-41d7-aa49-8c712631c231",
   "metadata": {},
   "source": [
    "### What is a layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cc6929-a833-410e-8dd5-bddb9e9d3a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://s7280.pcdn.co/wp-content/uploads/2020/07/Two-or-more-hidden-layers-comprise-a-Deep-Neural-Network.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"450px\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d79fb0-a40a-4916-914c-33a05812bf51",
   "metadata": {},
   "source": [
    "### What is a \"fully connected\" or \"linear\" layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac00d95-5ae7-4d6c-91bb-228a2b43e050",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://discuss.pytorch.org/uploads/default/original/1X/7e3dfc25dd2eda83d45adcd3d3d6d10f6c5636c3.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"450px\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45db9cd-e8c4-4558-baf9-6834962ddee9",
   "metadata": {},
   "source": [
    "### What is an \"activation function\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a0cba-e725-4d89-bad6-0ed037b82d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://miro.medium.com/v2/resize:fit:1200/1*ZafDv3VUm60Eh10OeJu1vw.png'\n",
    "display(HTML(f'<img src=\"{url}\" width=\"600px\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c140fa92-89ce-430d-bbd5-92a275bb9b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input values and their corresponding ReLU outputs\n",
    "data = {\n",
    "    \"Input (x)\": [-3, 0, 2, 10],\n",
    "    \"ReLU Output\": [max(0, x) for x in [-3, 0, 2, 10]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7eedf-cfcb-4dc4-af36-fa9175fb02c0",
   "metadata": {},
   "source": [
    "### How to define a model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackWhiteModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlackWhiteModel, self).__init__()\n",
    "        \n",
    "        num_classes = 10 \n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9159052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (start) your model with random weights \n",
    "net = BlackWhiteModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d27932",
   "metadata": {},
   "source": [
    "### Run an example image through an untrained model, just for experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea2f70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of basic usage\n",
    "net.eval()  # put model into eval mode (the is the prediction mode, not the training mode)\n",
    "img_input = img_batch[0].reshape((1, 1, 28, 28))  # make a batch of 1 from our image from dataloader, above\n",
    "output = net(img_input)  # run image through model and get a set of logits, 1 for each class category\n",
    "print(output)  # print logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66875f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply softmax to get probabilities for each class category\n",
    "probs = F.softmax(output[0], dim=0)\n",
    "print(probs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return predicted class\n",
    "max_logit, pred_class = output.max(dim=1) # predicts class\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370599f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class = output.argmax()  # also accomplishes the same thing\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a27fc4",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "\n",
    "Train the model for a a few epochs and see if it can accurately predict the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dc66a4-1295-4edb-9b65-38117735feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://assets.alexandria.raywenderlich.com/books/mlt/images/35e18ca4e4a896359297f9563f925b77e3294d5e1fbdc5f8e6cfa9e208e3a48d/original.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"350px\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad049ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the training loop, with only training data but not validation data \n",
    "# (easier to understand at first)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a86d159",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()  # put model into eval mode (the is the prediction mode, not the training mode)\n",
    "img_input = img_batch[0].reshape((1, 1, 28, 28))  # make a batch of 1 from our image from dataloader, above\n",
    "output = net(img_input)  # run image through model and get a set of logits, 1 for each class category\n",
    "print(output)  # print logits\n",
    "pred_class = output.argmax()  # also accomplishes the same thing\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15676278-350e-4be2-8c3c-4b10c1645334",
   "metadata": {},
   "source": [
    "### ðŸ€ Basketball Analogy: \n",
    "\n",
    "#### Breakdown of Roles in Training vs. Basketball\n",
    "\n",
    "| Machine Learning Process  | Basketball Analogy                         |\n",
    "|--------------------------|--------------------------------------------|\n",
    "| **Model's weights**      | Your muscle memory & technique            |\n",
    "| **Forward pass**         | Taking a shot                             |\n",
    "| **Loss function**        | Coach telling you how far you missed      |\n",
    "| **Backpropagation**      | Understanding why you missed (too much force, wrong angle) |\n",
    "| **Optimizer**            | Adjusting your shot technique (tweaking weight, aim, force) |\n",
    "\n",
    "---\n",
    "\n",
    "#### Example: Shooting Free Throws\n",
    "\n",
    "1. **You take a shot.** ðŸ€ *(Forward pass: model makes a prediction.)*  \n",
    "2. **The coach tells you, \"You missed by 3 inches to the left.\"** âŒ *(Loss function measures error.)*  \n",
    "3. **You think about why you missed.** ðŸ¤” *(Backpropagation computes needed corrections.)*  \n",
    "4. **You adjust your form: aim slightly to the right, apply less force.** ðŸ”„ *(Optimizer updates model weights.)*  \n",
    "5. **You take another shot, now it's closer to the basket!** âœ… *(Model is improved.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9bde7",
   "metadata": {},
   "source": [
    "# THE ALMIGHTY TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581fd333",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "min_valid_loss = np.inf  # keeps track of minimum validation loss so we know when to save model\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    \n",
    "    ##### TRAINING #####\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for data, labels in train_dataloader:\n",
    "        if torch.cuda.is_available():  # this only runs if you're running this on a GPU \n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = net(data)\n",
    "        loss = criterion(target, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    ##### VALIDATION #####\n",
    "    valid_loss = 0.0\n",
    "    net.eval()     # put model in eval mode\n",
    "    for data, labels in val_dataloader:\n",
    "        if torch.cuda.is_available(): # this only runs if you're running this on a GPU \n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = net(data)\n",
    "        loss = criterion(target, labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "    ##### PRINT STATS & SAVE MODEL #####\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_dataloader)}',\n",
    "          f'\\t\\t Validation Loss: {valid_loss / len(val_dataloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict (weights)\n",
    "        model_filename = os.path.join(data_dir, 'bw_model_weights.pth')\n",
    "        torch.save(net.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50342dec",
   "metadata": {},
   "source": [
    "## Run trained model on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106f8c3-dac4-409c-b020-3e8aae8f96df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from test set\n",
    "test_file = \"/Users/amc/Downloads/digit-recognizer/test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "print(f\"length of test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2cac13-2121-4a86-86e2-1d7bcc597653",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one image from test set\n",
    "idx = 0\n",
    "test_image = test_df.iloc[idx].to_numpy() \n",
    "test_image = test_image.reshape(28,28)\n",
    "\n",
    "# print image\n",
    "plt.imshow(test_image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760647dd-92f8-4e72-af6a-e8094959459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image into batched float tensor for model compatibility\n",
    "test_image_tensor = torch.from_numpy(test_image) \n",
    "test_image_tensor = test_image_tensor.float() \n",
    "test_image_tensor = test_image_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c98b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "trained_net = BlackWhiteModel()\n",
    "model_filename = os.path.join(data_dir, 'bw_model_weights.pth')\n",
    "trained_net.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# Make prediction (inference)\n",
    "trained_net.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    output = trained_net(test_image_tensor)\n",
    "    pred_class = output.argmax()\n",
    "\n",
    "print(\"Predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58182ee2-40eb-4f2a-937a-c9b5205ffd4b",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "ðŸš€ Why use `torch.no_grad()`?\n",
    "- Faster Inference\n",
    "- Lower Memory Consumption\n",
    "- No Risk of Accidental Gradient Tracking\n",
    "\n",
    "Always a good practice to use both `.eval()` and `.no_grad()` together for efficient and correct inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b636a37-c6ba-4583-921c-e51d89e60cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

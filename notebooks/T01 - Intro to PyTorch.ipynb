{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b10504",
   "metadata": {},
   "source": [
    "# Digit Recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba7bcc3",
   "metadata": {},
   "source": [
    "## 1. Download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853edec",
   "metadata": {},
   "source": [
    "[Kaggle Page](https://www.kaggle.com/competitions/digit-recognizer/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dd160d",
   "metadata": {},
   "source": [
    "## 2. Reformat the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f9fa4d",
   "metadata": {},
   "source": [
    "We must reformat the data so that we can look at a single image/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install matplotlib pandas torch torchvision Pillow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e93545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bb6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open csv as pandas dataframe\n",
    "data_dir = \"/Users/amc/Downloads/digit-recognizer\"\n",
    "train_file = os.path.join(data_dir, \"train.csv\")\n",
    "train_df = pd.read_csv(train_file)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e29598b",
   "metadata": {},
   "source": [
    "### Split up data into train/val subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f46ae42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split labels as an array (could probably be a list instead if you prefer)\n",
    "y = train_df['label']\n",
    "\n",
    "# split pixel info as an array\n",
    "X = train_df.drop(columns=['label'])\n",
    "\n",
    "# split data into train/val/test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, \n",
    "                                                    test_size=0.4, \n",
    "                                                    random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2335b769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train set: 25200\n",
      "length of val set: 16800\n"
     ]
    }
   ],
   "source": [
    "# check lengths of datasets\n",
    "print(f\"length of train set: {len(y_train)}\")\n",
    "print(f\"length of val set: {len(y_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963d69e1-b577-4861-9497-a8146be43cd5",
   "metadata": {},
   "source": [
    "### Write new dataframes to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e245218-43e3-494f-ac27-9ff2bd55cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/amc/Downloads/digit-recognizer/processed\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# merge back into dataframes\n",
    "column_names = train_df.columns.tolist()\n",
    "train_df = pd.concat([y_train, X_train], axis=1)\n",
    "val_df = pd.concat([y_val, X_val], axis=1)\n",
    "\n",
    "# save to csv files for loading into separate Dataset objects\n",
    "train_df.to_csv(os.path.join(data_dir, \"train.csv\"), index=False)\n",
    "val_df.to_csv(os.path.join(data_dir, \"val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1140534",
   "metadata": {},
   "source": [
    "### Withdraw 1 image+label pair for a given row (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f42466a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify index (row number, starting at 0)\n",
    "idx = 14\n",
    "\n",
    "# save and print label\n",
    "label = train_df.iloc[idx]['label']\n",
    "\n",
    "# save and print image with matplotlib pyplot\n",
    "image = train_df.iloc[idx].to_numpy()  # <- save row as numpy array\n",
    "image = image[1:]  # <- remove label value\n",
    "image = image.reshape(28,28)  # <- reshape numpy array into a 28x28 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e7c4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 9\n"
     ]
    }
   ],
   "source": [
    "# display image+label pair\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n",
    "print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9a3c5",
   "metadata": {},
   "source": [
    "## 3. Make a custom PyTorch Dataset class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac5629",
   "metadata": {},
   "source": [
    "The PyTorch Dataset class automates what we did above.\n",
    "\n",
    "This is a class where you define how to get the image and label for any given index. \n",
    "\n",
    "The index starts at 0 and ends at x-1, where x=number of total samples\n",
    "\n",
    "PyTorch tutorial: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8761099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitsDataset(Dataset):\n",
    "    def __init__(self, csv_file: str, transform=None):\n",
    "        \"\"\" Dataset of grayscale number images.\n",
    "        \n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            transform (callable, optional): Data transform.\n",
    "        \"\"\"\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):  \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):  \n",
    "        \n",
    "        # Extract label\n",
    "        label = self.df.iloc[idx]['label']\n",
    "        \n",
    "        # Extract image\n",
    "        image = self.df.iloc[idx].to_numpy(dtype=np.float32)  \n",
    "        image = image[1:]\n",
    "        image = image.reshape(28,28)\n",
    "        \n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a331f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the datasets\n",
    "train_dataset = DigitsDataset(csv_file=os.path.join(data_dir, \"train.csv\"), \n",
    "                              transform=T.Compose([\n",
    "                                  T.ToTensor()\n",
    "                              ]))\n",
    "val_dataset = DigitsDataset(csv_file=os.path.join(data_dir, \"val.csv\"), \n",
    "                            transform=T.Compose([\n",
    "                                T.ToTensor()\n",
    "                            ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec82e6",
   "metadata": {},
   "source": [
    "## 4. Make PyTorch DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834bf0d",
   "metadata": {},
   "source": [
    "The PyTorch DataLoader is a class where you specify batch number and it hands a batch of images for processing through the model. \n",
    "\n",
    "A batch is a set of images to be used for each training iteration. The number of images used for each batch is the batch size. \n",
    "\n",
    "Each training iteration is an \"epoch\", which is where the computer runs through all the images in the dataset once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b172454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b1477a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# view an image from the dataloader (NOTE: only works if num_workers=0)\n",
    "img_batch, label_batch = next(iter(train_dataloader))\n",
    "example_label = label_batch[0]\n",
    "example_img = img_batch[0].squeeze()\n",
    "\n",
    "# show image\n",
    "plt.imshow(example_img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {example_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1dd624",
   "metadata": {},
   "source": [
    "## 5. Make a model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f2549-7d3f-41d7-aa49-8c712631c231",
   "metadata": {},
   "source": [
    "### What is a layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17cc6929-a833-410e-8dd5-bddb9e9d3a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://s7280.pcdn.co/wp-content/uploads/2020/07/Two-or-more-hidden-layers-comprise-a-Deep-Neural-Network.png\" width=\"450px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://s7280.pcdn.co/wp-content/uploads/2020/07/Two-or-more-hidden-layers-comprise-a-Deep-Neural-Network.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"450px\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d79fb0-a40a-4916-914c-33a05812bf51",
   "metadata": {},
   "source": [
    "### What is a \"fully connected\" or \"linear\" layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ac00d95-5ae7-4d6c-91bb-228a2b43e050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://discuss.pytorch.org/uploads/default/original/1X/7e3dfc25dd2eda83d45adcd3d3d6d10f6c5636c3.png\" width=\"450px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://discuss.pytorch.org/uploads/default/original/1X/7e3dfc25dd2eda83d45adcd3d3d6d10f6c5636c3.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"450px\">'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45db9cd-e8c4-4558-baf9-6834962ddee9",
   "metadata": {},
   "source": [
    "### What is an \"activation function\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed7a0cba-e725-4d89-bad6-0ed037b82d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:1200/1*ZafDv3VUm60Eh10OeJu1vw.png\" width=\"600px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'https://miro.medium.com/v2/resize:fit:1200/1*ZafDv3VUm60Eh10OeJu1vw.png'\n",
    "display(HTML(f'<img src=\"{url}\" width=\"600px\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c140fa92-89ce-430d-bbd5-92a275bb9b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input (x)</th>\n",
       "      <th>ReLU Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Input (x)  ReLU Output\n",
       "0         -3            0\n",
       "1          0            0\n",
       "2          2            2\n",
       "3         10           10"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input values and their corresponding ReLU outputs\n",
    "data = {\n",
    "    \"Input (x)\": [-3, 0, 2, 10],\n",
    "    \"ReLU Output\": [max(0, x) for x in [-3, 0, 2, 10]]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf7eedf-cfcb-4dc4-af36-fa9175fb02c0",
   "metadata": {},
   "source": [
    "### How to define a model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b376f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackWhiteModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BlackWhiteModel, self).__init__()\n",
    "        \n",
    "        num_classes = 10 \n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9159052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize (start) your model with random weights \n",
    "net = BlackWhiteModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d27932",
   "metadata": {},
   "source": [
    "### Run an example image through an untrained model, just for experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dea2f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0924,  0.9871, -0.7274, -0.4186,  0.4789,  1.2431,  0.3405, -0.3878,\n",
      "         -5.2049,  1.3560]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of basic usage\n",
    "net.eval()  # put model into eval mode (the is the prediction mode, not the training mode)\n",
    "img_input = img_batch[0].reshape((1, 1, 28, 28))  # make a batch of 1 from our image from dataloader, above\n",
    "output = net(img_input)  # run image through model and get a set of logits, 1 for each class category\n",
    "print(output)  # print logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66875f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0030, 0.1798, 0.0324, 0.0441, 0.1082, 0.2323, 0.0942, 0.0455, 0.0004,\n",
      "        0.2601], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# apply softmax to get probabilities for each class category\n",
    "probs = F.softmax(output[0], dim=0)\n",
    "print(probs)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43cfdcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9\n"
     ]
    }
   ],
   "source": [
    "# return predicted class\n",
    "max_logit, pred_class = output.max(dim=1) # predicts class\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "370599f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class: 9\n"
     ]
    }
   ],
   "source": [
    "pred_class = output.argmax()  # also accomplishes the same thing\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a27fc4",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "\n",
    "Train the model for a a few epochs and see if it can accurately predict the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97dc66a4-1295-4edb-9b65-38117735feb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://assets.alexandria.raywenderlich.com/books/mlt/images/35e18ca4e4a896359297f9563f925b77e3294d5e1fbdc5f8e6cfa9e208e3a48d/original.png\" width=\"350px\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://assets.alexandria.raywenderlich.com/books/mlt/images/35e18ca4e4a896359297f9563f925b77e3294d5e1fbdc5f8e6cfa9e208e3a48d/original.png\"\n",
    "display(HTML(f'<img src=\"{url}\" width=\"350px\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6b7f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fad049ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.653\n",
      "[2,  2000] loss: 0.586\n",
      "[3,  2000] loss: 0.400\n",
      "[4,  2000] loss: 0.316\n",
      "[5,  2000] loss: 0.267\n",
      "[6,  2000] loss: 0.229\n",
      "[7,  2000] loss: 0.202\n",
      "[8,  2000] loss: 0.180\n",
      "[9,  2000] loss: 0.161\n",
      "[10,  2000] loss: 0.148\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# run the training loop, with only training data but not validation data \n",
    "# (easier to understand at first)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a86d159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.7791, -6.2812, -4.9105,  1.5484, -7.9293,  9.3983, -6.9025, -0.2642,\n",
      "          2.2554, -4.9650]], grad_fn=<AddmmBackward0>)\n",
      "predicted class: 5\n"
     ]
    }
   ],
   "source": [
    "net.eval()  # put model into eval mode (the is the prediction mode, not the training mode)\n",
    "img_input = img_batch[0].reshape((1, 1, 28, 28))  # make a batch of 1 from our image from dataloader, above\n",
    "output = net(img_input)  # run image through model and get a set of logits, 1 for each class category\n",
    "print(output)  # print logits\n",
    "pred_class = output.argmax()  # also accomplishes the same thing\n",
    "print(\"predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15676278-350e-4be2-8c3c-4b10c1645334",
   "metadata": {},
   "source": [
    "### ðŸ€ Basketball Analogy: \n",
    "\n",
    "#### Breakdown of Roles in Training vs. Basketball\n",
    "\n",
    "| Machine Learning Process  | Basketball Analogy                         |\n",
    "|--------------------------|--------------------------------------------|\n",
    "| **Model's weights**      | Your muscle memory & technique            |\n",
    "| **Forward pass**         | Taking a shot                             |\n",
    "| **Loss function**        | Coach telling you how far you missed      |\n",
    "| **Backpropagation**      | Understanding why you missed (too much force, wrong angle) |\n",
    "| **Optimizer**            | Adjusting your shot technique (tweaking weight, aim, force) |\n",
    "\n",
    "---\n",
    "\n",
    "#### Example: Shooting Free Throws\n",
    "\n",
    "1. **You take a shot.** ðŸ€ *(Forward pass: model makes a prediction.)*  \n",
    "2. **The coach tells you, \"You missed by 3 inches to the left.\"** âŒ *(Loss function measures error.)*  \n",
    "3. **You think about why you missed.** ðŸ¤” *(Backpropagation computes needed corrections.)*  \n",
    "4. **You adjust your form: aim slightly to the right, apply less force.** ðŸ”„ *(Optimizer updates model weights.)*  \n",
    "5. **You take another shot, now it's closer to the basket!** âœ… *(Model is improved.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e9bde7",
   "metadata": {},
   "source": [
    "# THE ALMIGHTY TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "581fd333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \t\t Training Loss: 0.13609033878867252 \t\t Validation Loss: 0.0002394480231617178\n",
      "Validation Loss Decreased(inf--->0.402273) \t Saving The Model\n",
      "Epoch 2 \t\t Training Loss: 0.1251609454183453 \t\t Validation Loss: 0.0001646237935693491\n",
      "Validation Loss Decreased(0.402273--->0.276568) \t Saving The Model\n",
      "Epoch 3 \t\t Training Loss: 0.11545588363958467 \t\t Validation Loss: 0.0002711326593444461\n",
      "Epoch 4 \t\t Training Loss: 0.10625343190871978 \t\t Validation Loss: 0.00023757870353403545\n",
      "Epoch 5 \t\t Training Loss: 0.09821065166211661 \t\t Validation Loss: 0.00023764875229625475\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "min_valid_loss = np.inf  # keeps track of minimum validation loss so we know when to save model\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    \n",
    "    ##### TRAINING #####\n",
    "    train_loss = 0.0\n",
    "    net.train()\n",
    "    for data, labels in train_dataloader:\n",
    "        if torch.cuda.is_available():  # this only runs if you're running this on a GPU \n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        target = net(data)\n",
    "        loss = criterion(target, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    ##### VALIDATION #####\n",
    "    valid_loss = 0.0\n",
    "    net.eval()     # put model in eval mode\n",
    "    for data, labels in val_dataloader:\n",
    "        if torch.cuda.is_available(): # this only runs if you're running this on a GPU \n",
    "            data, labels = data.cuda(), labels.cuda()\n",
    "        \n",
    "        target = net(data)\n",
    "        loss = criterion(target, labels)\n",
    "        valid_loss = loss.item() * data.size(0)\n",
    "\n",
    "    ##### PRINT STATS & SAVE MODEL #####\n",
    "    print(f'Epoch {e+1} \\t\\t Training Loss: {train_loss / len(train_dataloader)}',\n",
    "          f'\\t\\t Validation Loss: {valid_loss / len(val_dataloader)}')\n",
    "    if min_valid_loss > valid_loss:\n",
    "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{valid_loss:.6f}) \\t Saving The Model')\n",
    "        min_valid_loss = valid_loss\n",
    "        # Saving State Dict (weights)\n",
    "        model_filename = os.path.join(data_dir, 'bw_model_weights.pth')\n",
    "        torch.save(net.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50342dec",
   "metadata": {},
   "source": [
    "## Run trained model on a test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b106f8c3-dac4-409c-b020-3e8aae8f96df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of test set: 28000\n"
     ]
    }
   ],
   "source": [
    "# Load data from test set\n",
    "test_file = \"/Users/amc/Downloads/digit-recognizer/test.csv\"\n",
    "test_df = pd.read_csv(test_file)\n",
    "print(f\"length of test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f2cac13-2121-4a86-86e2-1d7bcc597653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28000 rows Ã— 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27995       0       0       0       0       0       0       0       0       0   \n",
       "27996       0       0       0       0       0       0       0       0       0   \n",
       "27997       0       0       0       0       0       0       0       0       0   \n",
       "27998       0       0       0       0       0       0       0       0       0   \n",
       "27999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27995       0  ...         0         0         0         0         0   \n",
       "27996       0  ...         0         0         0         0         0   \n",
       "27997       0  ...         0         0         0         0         0   \n",
       "27998       0  ...         0         0         0         0         0   \n",
       "27999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27995         0         0         0         0         0  \n",
       "27996         0         0         0         0         0  \n",
       "27997         0         0         0         0         0  \n",
       "27998         0         0         0         0         0  \n",
       "27999         0         0         0         0         0  \n",
       "\n",
       "[28000 rows x 784 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56afd8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get one image from test set\n",
    "idx = 0\n",
    "test_image = test_df.iloc[idx].to_numpy() \n",
    "test_image = test_image.reshape(28,28)\n",
    "\n",
    "# print image\n",
    "plt.imshow(test_image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "760647dd-92f8-4e72-af6a-e8094959459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image into batched float tensor for model compatibility\n",
    "test_image_tensor = torch.from_numpy(test_image) \n",
    "test_image_tensor = test_image_tensor.float() \n",
    "test_image_tensor = test_image_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79c98b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2\n"
     ]
    }
   ],
   "source": [
    "# Load saved model\n",
    "trained_net = BlackWhiteModel()\n",
    "model_filename = os.path.join(data_dir, 'bw_model_weights.pth')\n",
    "trained_net.load_state_dict(torch.load(model_filename))\n",
    "\n",
    "# Make prediction (inference)\n",
    "trained_net.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculations\n",
    "    output = trained_net(test_image_tensor)\n",
    "    pred_class = output.argmax()\n",
    "\n",
    "print(\"Predicted class:\", int(pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58182ee2-40eb-4f2a-937a-c9b5205ffd4b",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "ðŸš€ Why use `torch.no_grad()`?\n",
    "- Faster Inference\n",
    "- Lower Memory Consumption\n",
    "- No Risk of Accidental Gradient Tracking\n",
    "\n",
    "Always a good practice to use both `.eval()` and `.no_grad()` together for efficient and correct inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b636a37-c6ba-4583-921c-e51d89e60cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
